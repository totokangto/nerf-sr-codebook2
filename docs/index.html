
<!DOCTYPE html>
<html>

<head lang="en">
    <meta charset="UTF-8">
    <meta http-equiv="x-ua-compatible" content="ie=edge">

    <title>NeRF-SR</title>

    <meta name="description" content="">
    <meta name="viewport" content="width=device-width, initial-scale=1">


<!--     <link rel="apple-touch-icon" href="apple-touch-icon.png"> -->
<!--   <link rel="icon" type="image/png" href="img/seal_icon.png"> -->
    <!-- Place favicon.ico in the root directory -->

    <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.5/css/bootstrap.min.css">
    <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/font-awesome/4.4.0/css/font-awesome.min.css">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/codemirror/5.8.0/codemirror.min.css">
    <link rel="stylesheet" href="css/app.css">

    <link rel="stylesheet" href="css/bootstrap.min.css">


    <script src="https://ajax.googleapis.com/ajax/libs/jquery/1.11.3/jquery.min.js"></script>
    <script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.5/js/bootstrap.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/codemirror/5.8.0/codemirror.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/1.5.3/clipboard.min.js"></script>
    
    <script src="js/app.js"></script>
    
    <!-- Global site tag (gtag.js) - Google Analytics -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-2SC7YQN2LP"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());

      gtag('config', 'G-2SC7YQN2LP');
    </script>

</head>

<body>
    <div class="container" id="main">
        <div class="row">
            <h2 class="col-md-12 text-center">
                NeRF-SR: High-Quality Neural Radiance Fields using Super-Sampling<br>
                <small>
                    ACM Multimedia 2022
                </small>
            </h2>
        </div>
        <div class="row">
            <div class="col-md-12 text-center">
                <ul class="list-inline">
                    <li>
                        <a href="https://cwchenwang.github.io/">
                            Chen Wang
                        </a>
                    </li>
                    <li>
                        <a href="/">
                          Xian Wu
                        </a>
                    </li>
                    <li>
                        <a href="/">
                          Yuan-Chen Guo
                        </a>
                    </li>
                    <li>
                        <a href="/">
                          Song-Hai Zhang
                        </a>
                    </li>
                    <li>
                        <a href="/">
                          Yu-Wing Tai
                        </a>
                    </li>
                    <li>
                        <a href="https://cg.cs.tsinghua.edu.cn">
                          Shi-Min Hu
                        </a>
                    </li>
                </ul>

                <ul class="list-inline">
                    <li>
                        Tsinghua University
                    </li>
                    <li>
                        Kuaishou Technology
                    </li>
                    <li>
                        HKUST
                    </li>
                </ul>
            </div>
        </div>


        <div class="row">
                <div class="col-md-4 col-md-offset-4 text-center">
                    <ul class="nav nav-pills nav-justified">
                        <li>
                            <a href="https://arxiv.org/abs/2112.01759">
                            <image src="img/nerf-sr_paper_thumbnail.png" height="60px">
                                <h4><strong>Paper</strong></h4>
                            </a>
                        </li>
                        <li>
                            <a href="data/supp.pdf">
                            <image src="img/nerf-sr_supp_thumbnail.png" height="60px">
                                <h4><strong>Supp</strong></h4>
                            </a>
                        </li>
                        <li>
                            <a href="https://youtu.be/c3Yx2nGvi8o">
                            <image src="img/youtube_icon.png" height="60px"><br>
                                <h4><strong>Video</strong></h4>
                            </a>
                        </li>
                        <li>
                            <a href="https://github.com/cwchenwang/NeRF-SR">
                            <image src="img/github.png" height="60px">
                                <h4><strong>Code</strong></h4>
                            </a>
                        </li>
                    </ul>
                </div>
        </div>



        <div class="row">
            <div class="col-md-8 col-md-offset-2">
                <h3>
                    Abstract
                </h3>
                <p class="text-justify">
                    We present NeRF-SR, a solution for high-resolution (HR) novel view synthesis with mostly low-resolution (LR) inputs. Our method is built upon Neural Radiance Fields (NeRF) \cite{mildenhall2020nerf} that predicts per-point density and color with a multi-layer perceptron. While producing images at arbitrary scales, NeRF struggles with resolutions that go beyond observed images. Our key insight is that NeRF benefits from 3D consistency, which means an observed pixel absorbs information from nearby views. We first exploit it by a super-sampling strategy that shoots multiple rays at each image pixel, which further enforces multi-view constraint at a sub-pixel level. Then, we show that NeRF-SR can further boost the performance of super-sampling by a refinement network that leverages the estimated depth at hand to hallucinate details from related patches on an HR reference image. Experiment results demonstrate that NeRF-SR generates high-quality results for novel view synthesis at HR on both synthetic and real-world datasets.
                </p>
                <image src="img/pipeline.png" class="img-responsive" alt="overview">
            </div>
        </div>


        <div class="row">
            <div class="col-md-8 col-md-offset-2">
                <h3>
                    Video
                </h3>
                <div class="text-center">
                    <div style="position:relative;padding-top:56.25%;">
                        <iframe src="https://www.youtube.com/embed/c3Yx2nGvi8o" allowfullscreen style="position:absolute;top:0;left:0;width:100%;height:100%;"></iframe>
                    </div>
                </div>
            </div>
        </div>
            

        <div class="row">
            <div class="col-md-8 col-md-offset-2">
                <h3>
                    Results
                </h3>
                <p class="text-justify">
                    NeRF-SR find sub-pixel level correspondence through super-sampling, which means missing details in the input can be found from other views that lie in the neighboring region in 3D space. Vanilla NeRF and bicubic produces blurry results. NeRF-SR relies purely on the input images of the scene and doesn't require any external priors.
                </p>                
                <br>
                <video id="v0" width="100%" autoplay loop muted controls>
                    <source src="img/comparison.mp4" type="video/mp4" />
                </video>
                <image src="img/blender.png" class="img-responsive" alt="blender"></image>
                <image src="img/llff.png" class="img-responsive" alt="llff"></image>
                <br>
            </div>
        </div>

        <div class="row">
            <div class="col-md-8 col-md-offset-2">
                <h3>
                    Citation
                </h3>
                <div class="form-group col-md-10 col-md-offset-1">
                    <textarea id="bibtex" class="form-control" readonly>
@article{wang2021nerf-sr,
    title={NeRF-SR: High-Quality Neural Radiance Fields 
            using Super-Sampling},
    author={Chen Wang and Xian Wu and 
            Yuan-Chen Guo and Song-Hai Zhang and 
            Yu-Wing Tai and Shi-Min Hu},
    journal={arXiv},
    year={2021}
}</textarea>
            </div>
        </div>
    </div>

        <div class="row">
            <div class="col-md-8 col-md-offset-2">
                <h3>
                    Acknowledgement
                </h3>
                <p class="text-justify">      
                The website template was borrowed from <a href="http://mgharbi.com/">MichaÃ«l Gharbi</a> and <a href="https://bmild.github.io/">Ben Mildenhall</a>.
                </p>
            </div>
        </div>
    </div>
</body>
</html>
